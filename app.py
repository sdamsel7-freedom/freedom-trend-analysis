import streamlit as st
import pandas as pd
import requests
import json
from datetime import datetime
import io

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="í”„ë¦¬ë¤ íŠ¸ë Œë“œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ğŸƒâ€â™‚ï¸ Freedom Trend Analysis Dashboard")
st.markdown("### 19~44ì„¸ ë‚¨ë…€ íŠ¸ë Œë“œ ë¶„ì„ ë° ìŠ¤ì¼€ì¼ ë³´ì • ë„êµ¬")

# 2. ë³´ì•ˆ ì„¤ì • (Secrets)
try:
    CLIENT_ID = st.secrets["NAVER_CLIENT_ID"]
    CLIENT_SECRET = st.secrets["NAVER_CLIENT_SECRET"]
except KeyError:
    st.error("ì˜¤ë¥˜: Streamlit Secretsì— API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()

# 3. Naver API í˜¸ì¶œ í•¨ìˆ˜
def get_api_data(keyword_groups, gender):
    url = "https://openapi.naver.com/v1/datalab/search"
    headers = {
        "X-Naver-Client-Id": CLIENT_ID,
        "X-Naver-Client-Secret": CLIENT_SECRET,
        "Content-Type": "application/json"
    }
    body = {
        "startDate": "2024-01-01",
        "endDate": datetime.now().strftime("%Y-%m-%d"),
        "timeUnit": "month",
        "keywordGroups": keyword_groups,
        "device": "",
        "ages": ["3", "4", "5", "6", "7"], # 19~44ì„¸ íƒ€ê²ŸíŒ…
        "gender": gender
    }
    response = requests.post(url, headers=headers, data=json.dumps(body))
    if response.status_code == 200:
        res_json = response.json()
        data_list = []
        for group in res_json['results']:
            if 'data' in group and group['data']:
                for entry in group['data']:
                    data_list.append({
                        'Date': entry['period'],
                        'Keyword_Group': group['title'],
                        'Ratio': entry['ratio'],
                        'Gender': 'Male' if gender == 'm' else 'Female'
                    })
        return pd.DataFrame(data_list)
    return pd.DataFrame()

# 4. ì‚¬ì´ë“œë°”: ì–‘ì‹ ë‹¤ìš´ë¡œë“œ ë° íŒŒì¼ ì—…ë¡œë“œ
with st.sidebar:
    st.header("ğŸ“ ë°ì´í„° ê´€ë¦¬")
    
    # [ë‹¤ì‹œ ì¶”ê°€ëœ ê¸°ëŠ¥] ì—‘ì…€ ì–‘ì‹ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    st.subheader("1. ì–‘ì‹ ë°›ê¸°")
    try:
        with open("keywords_input.xlsx", "rb") as f:
            st.download_button(
                label="ğŸ“¥ ë¶„ì„ ì–‘ì‹(Excel) ë‹¤ìš´ë¡œë“œ",
                data=f,
                file_name="keywords_input.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        st.caption("íŒ€ì›ë“¤ì€ ì´ ì–‘ì‹ì„ ë°›ì•„ ì‘ì„± í›„ ì•„ë˜ì— ì—…ë¡œë“œí•˜ì„¸ìš”.")
    except FileNotFoundError:
        st.warning("ì €ì¥ì†Œì— keywords_input.xlsx íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    st.divider()
    
    # íŒŒì¼ ì—…ë¡œë“œ
    st.subheader("2. ë°ì´í„° ë¶„ì„")
    uploaded_file = st.file_uploader("ìˆ˜ì •í•˜ì‹  ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["xlsx"])

# 5. ë©”ì¸ ë¡œì§
if uploaded_file:
    df_input = pd.read_excel(uploaded_file)
    
    if 'GroupName' in df_input.columns:
        all_groups = []
        for _, row in df_input.iterrows():
            g_name = str(row['GroupName']).strip()
            # ë¹ˆ í–‰ì´ë‚˜ '*'ë¡œ ì‹œì‘í•˜ëŠ” ë©”ëª¨ í–‰ ê±´ë„ˆë›°ê¸°
            if not g_name or g_name.startswith('*') or g_name == "nan":
                continue
            
            kw_val = str(row['Keywords']).strip() if 'Keywords' in df_input.columns and pd.notnull(row['Keywords']) else ""
            keywords = [k.strip() for k in kw_val.split(',')] if kw_val and kw_val != "nan" else [g_name]
            all_groups.append({"groupName": g_name, "keywords": keywords})

        if not all_groups:
            st.error("ë¶„ì„í•  ìœ íš¨í•œ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            anchor_group = all_groups[0]
            anchor_name = anchor_group['groupName']
            other_groups = all_groups[1:]

            if st.sidebar.button("ğŸš€ ë¶„ì„ ì‹œì‘ (Run Analysis)"):
                final_df = pd.DataFrame()
                reference_data = pd.DataFrame()
                progress = st.progress(0)
                
                batch_size = 4
                for i in range(0, len(other_groups) if other_groups else 1, batch_size):
                    chunk = other_groups[i:i+batch_size]
                    current_batch = [anchor_group] + chunk
                    batch_res = pd.concat([get_api_data(current_batch, 'm'), get_api_data(current_batch, 'f')], ignore_index=True)
                    
                    if batch_res.empty: continue

                    if i == 0 or reference_data.empty:
                        reference_data = batch_res[batch_res['Keyword_Group'] == anchor_name].copy()
                        final_df = batch_res
                    else:
                        curr_anchor = batch_res[batch_res['Keyword_Group'] == anchor_name].copy()
                        if not curr_anchor.empty:
                            scale_merge = pd.merge(curr_anchor, reference_data, on=['Date', 'Gender'], suffixes=('_curr', '_ref'))
                            if not scale_merge.empty:
                                scale_merge['Factor'] = scale_merge['Ratio_ref'] / scale_merge['Ratio_curr']
                                batch_res = pd.merge(batch_res, scale_merge[['Date', 'Gender', 'Factor']], on=['Date', 'Gender'])
                                batch_res['Ratio'] = batch_res['Ratio'] * batch_res['Factor']
                                final_df = pd.concat([final_df, batch_res[batch_res['Keyword_Group'] != anchor_name]], ignore_index=True)
                    progress.progress(min((i + batch_size) / (len(other_groups) + 1) if other_groups else 1.0, 1.0))

                if not final_df.empty:
                    st.session_state['analysis_result'] = final_df
                    st.session_state['anchor_name'] = anchor_name
                    st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

        # ë¶„ì„ ê²°ê³¼ í‘œì‹œ ë° í•„í„°/ë‹¤ìš´ë¡œë“œ ì„¹ì…˜
        if 'analysis_result' in st.session_state:
            res_df = st.session_state['analysis_result']
            anchor_name = st.session_state['anchor_name']
            
            st.divider()
            st.subheader("ğŸ¯ ê²°ê³¼ í•„í„°ë§ ë° ë‹¤ìš´ë¡œë“œ")
            
            available_keywords = res_df['Keyword_Group'].unique().tolist()
            selected_items = st.multiselect("í™”ë©´ì—ì„œ ë³´ê³  ì‹¶ì€ í‚¤ì›Œë“œë§Œ ì„ íƒí•˜ì„¸ìš”:", options=available_keywords, default=available_keywords)
            
            if selected_items:
                filtered_df = res_df[res_df['Keyword_Group'].isin(selected_items)]
                
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.subheader(f"ğŸ“Š ê²€ìƒ‰ íŠ¸ë Œë“œ (ê¸°ì¤€: {anchor_name})")
                    chart_data = filtered_df.pivot_table(index='Date', columns='Keyword_Group', values='Ratio', aggfunc='mean')
                    st.line_chart(chart_data)
                
                with col2:
                    st.subheader("ğŸ‘¥ ì„±ë³„ ë¹„ì¤‘ (í‰ê· )")
                    gender_stats = filtered_df.groupby('Gender')['Ratio'].mean()
                    st.write(gender_stats)

                # ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    filtered_df.to_excel(writer, index=False, sheet_name='Analysis_Result')
                
                st.download_button(
                    label="ğŸ“¥ ì„ íƒëœ ë¶„ì„ ê²°ê³¼ ì—‘ì…€ë¡œ ì €ì¥",
                    data=output.getvalue(),
                    file_name=f"freedom_trend_{datetime.now().strftime('%Y%m%d')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
                st.dataframe(filtered_df, use_container_width=True)
    else:
        st.error("ì—‘ì…€ íŒŒì¼ì— 'GroupName' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
else:
    st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ì–‘ì‹ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì‘ì„±í•œ ë’¤ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
