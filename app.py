import streamlit as st
import pandas as pd
import requests
import json
from datetime import datetime
import io

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="í”„ë¦¬ë¤ íŠ¸ë Œë“œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ğŸƒâ€â™‚ï¸ Freedom Trend Analysis Dashboard")

# 2. ë³´ì•ˆ ì„¤ì • (Secrets)
try:
    CLIENT_ID = st.secrets["NAVER_CLIENT_ID"]
    CLIENT_SECRET = st.secrets["NAVER_CLIENT_SECRET"]
except KeyError:
    st.error("ì˜¤ë¥˜: Streamlit Secrets ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# 3. Naver API í˜¸ì¶œ í•¨ìˆ˜
def get_api_data(keyword_groups, gender):
    url = "https://openapi.naver.com/v1/datalab/search"
    headers = {
        "X-Naver-Client-Id": CLIENT_ID,
        "X-Naver-Client-Secret": CLIENT_SECRET,
        "Content-Type": "application/json"
    }
    body = {
        "startDate": "2024-01-01",
        "endDate": datetime.now().strftime("%Y-%m-%d"),
        "timeUnit": "month",
        "keywordGroups": keyword_groups,
        "device": "",
        "ages": ["3", "4", "5", "6", "7"], # 19~44ì„¸ íƒ€ê²Ÿ
        "gender": gender
    }
    try:
        response = requests.post(url, headers=headers, data=json.dumps(body), timeout=15)
        if response.status_code == 200:
            res_json = response.json()
            data_list = []
            for group in res_json['results']:
                if 'data' in group and group['data']:
                    for entry in group['data']:
                        data_list.append({
                            'Date': entry['period'],
                            'Keyword_Group': group['title'],
                            'Ratio': entry['ratio'],
                            'Gender': 'Male' if gender == 'm' else 'Female'
                        })
            return pd.DataFrame(data_list)
    except Exception as e:
        st.sidebar.error(f"Error: {e}")
    return pd.DataFrame()

# 4. ì‚¬ì´ë“œë°” êµ¬ì„±
with st.sidebar:
    st.header("ğŸ“ ë°ì´í„° ê´€ë¦¬")
    try:
        with open("keywords_input.xlsx", "rb") as f:
            st.download_button("ğŸ“¥ ë¶„ì„ ì–‘ì‹(Excel) ë°›ê¸°", f, file_name="keywords_input.xlsx")
    except:
        pass
    st.divider()
    uploaded_file = st.file_uploader("ìˆ˜ì •í•˜ì‹  ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["xlsx"])

# 5. ë©”ì¸ ë¶„ì„ ë¡œì§
if uploaded_file:
    df_input = pd.read_excel(uploaded_file)
    name_col = next((c for c in df_input.columns if c.lower() in ['groupname', 'ê·¸ë£¹ëª…', 'í•­ëª©']), None)
    kw_col = next((c for c in df_input.columns if c.lower() in ['keywords', 'í‚¤ì›Œë“œ', 'ì—°ê´€ê²€ìƒ‰ì–´']), None)

    if name_col:
        all_groups = []
        for _, row in df_input.iterrows():
            g_name = str(row[name_col]).strip()
            if not g_name or g_name.startswith('*') or g_name == "nan": continue
            
            # [í•µì‹¬ ë¡œì§ ë³€ê²½] GroupNameì„ ê¸°ë³¸ ê²€ìƒ‰ì–´ë¡œ í¬í•¨
            keyword_list = [g_name]
            
            # Keywords ì»¬ëŸ¼ì— ì¶”ê°€ ê²€ìƒ‰ì–´ê°€ ìˆë‹¤ë©´ ë¦¬ìŠ¤íŠ¸ì— ë”í•´ì¤Œ
            raw_kws = str(row[kw_col]).strip() if kw_col and pd.notnull(row[kw_col]) else ""
            if raw_kws and raw_kws.lower() != "nan":
                extra_kws = [k.strip() for k in raw_kws.split(',') if k.strip()]
                keyword_list.extend(extra_kws)
            
            # ì¤‘ë³µ ë‹¨ì–´ ì œê±° (ìˆœì„œ ìœ ì§€)
            final_keywords = list(dict.fromkeys(keyword_list))
            all_groups.append({"groupName": g_name, "keywords": final_keywords})

        if all_groups:
            anchor_group = all_groups[0]
            anchor_name = anchor_group['groupName']
            other_groups = all_groups[1:]

            if st.sidebar.button("ğŸš€ ë¶„ì„ ì‹œì‘ (Run Analysis)"):
                final_df = pd.DataFrame()
                reference_data = pd.DataFrame()
                status = st.empty()
                progress = st.progress(0)
                
                batch_size = 4
                for i in range(0, len(other_groups) if other_groups else 1, batch_size):
                    chunk = other_groups[i:i+batch_size]
                    current_batch = [anchor_group] + chunk
                    status.text(f"â³ ë¶„ì„ ì¤‘: {anchor_name} + {', '.join([c['groupName'] for c in chunk])}")
                    
                    batch_res = pd.concat([get_api_data(current_batch, 'm'), get_api_data(current_batch, 'f')], ignore_index=True)
                    if batch_res.empty: continue

                    if i == 0 or reference_data.empty:
                        reference_data = batch_res[batch_res['Keyword_Group'] == anchor_name].copy()
                        final_df = batch_res
                    else:
                        curr_anchor = batch_res[batch_res['Keyword_Group'] == anchor_name].copy()
                        if not curr_anchor.empty and not reference_data.empty:
                            scale_merge = pd.merge(curr_anchor, reference_data, on=['Date', 'Gender'], suffixes=('_curr', '_ref'))
                            if not scale_merge.empty:
                                scale_merge['Factor'] = scale_merge['Ratio_ref'] / scale_merge['Ratio_curr']
                                batch_res = pd.merge(batch_res, scale_merge[['Date', 'Gender', 'Factor']], on=['Date', 'Gender'])
                                batch_res['Ratio'] = batch_res['Ratio'] * batch_res['Factor']
                                final_df = pd.concat([final_df, batch_res[batch_res['Keyword_Group'] != anchor_name]], ignore_index=True)
                    progress.progress(min((i + batch_size) / (len(other_groups) + 1) if other_groups else 1.0, 1.0))

                status.empty()
                if not final_df.empty:
                    st.session_state['analysis_result'] = final_df
                    st.session_state['anchor_name'] = anchor_name
                    st.success("âœ… ë¶„ì„ ì™„ë£Œ!")

        # 6. ê²°ê³¼ ì¶œë ¥
        if st.session_state.get('analysis_result') is not None:
            res_df = st.session_state['analysis_result']
            anchor_name = st.session_state['anchor_name']
            st.divider()
            available = res_df['Keyword_Group'].unique().tolist()
            selected = st.multiselect("ğŸ“ˆ í‘œì‹œí•  í•­ëª© ì„ íƒ:", options=available, default=available)
            if selected:
                f_df = res_df[res_df['Keyword_Group'].isin(selected)]
                chart_data = f_df.pivot_table(index='Date', columns='Keyword_Group', values='Ratio', aggfunc='mean')
                st.line_chart(chart_data)
                
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    f_df.to_excel(writer, index=False, sheet_name='Result')
                st.download_button("ğŸ“¥ ê²°ê³¼ ì—‘ì…€ ì €ì¥", output.getvalue(), file_name=f"freedom_trend_{datetime.now().strftime('%Y%m%d')}.xlsx")
                st.dataframe(f_df, use_container_width=True)
