import streamlit as st
import pandas as pd
import requests
import json
from datetime import datetime
import io

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="í”„ë¦¬ë¤ íŠ¸ë Œë“œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ğŸƒâ€â™‚ï¸ Freedom Trend Analysis Dashboard")

# 2. ë³´ì•ˆ ì„¤ì • (Secrets)
try:
    CLIENT_ID = st.secrets["NAVER_CLIENT_ID"]
    CLIENT_SECRET = st.secrets["NAVER_CLIENT_SECRET"]
except KeyError:
    st.error("ì˜¤ë¥˜: Streamlit Secretsì— API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()

# 3. Naver API í˜¸ì¶œ í•¨ìˆ˜
def get_api_data(keyword_groups, gender):
    url = "https://openapi.naver.com/v1/datalab/search"
    headers = {
        "X-Naver-Client-Id": CLIENT_ID,
        "X-Naver-Client-Secret": CLIENT_SECRET,
        "Content-Type": "application/json"
    }
    body = {
        "startDate": "2024-01-01",
        "endDate": datetime.now().strftime("%Y-%m-%d"),
        "timeUnit": "month",
        "keywordGroups": keyword_groups,
        "device": "",
        "ages": ["3", "4", "5", "6", "7"], # 19~44ì„¸ íƒ€ê²ŸíŒ…
        "gender": gender
    }
    try:
        response = requests.post(url, headers=headers, data=json.dumps(body), timeout=10)
        if response.status_code == 200:
            res_json = response.json()
            data_list = []
            for group in res_json['results']:
                if 'data' in group and group['data']:
                    for entry in group['data']:
                        data_list.append({
                            'Date': entry['period'],
                            'Keyword_Group': group['title'],
                            'Ratio': entry['ratio'],
                            'Gender': 'Male' if gender == 'm' else 'Female'
                        })
            return pd.DataFrame(data_list)
    except Exception as e:
        st.error(f"ì—°ê²° ì˜¤ë¥˜: {e}")
    return pd.DataFrame()

# 4. ì‚¬ì´ë“œë°” êµ¬ì„±
with st.sidebar:
    st.header("ğŸ“ ë°ì´í„° ê´€ë¦¬")
    
    # ì–‘ì‹ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ë³µêµ¬
    try:
        with open("keywords_input.xlsx", "rb") as f:
            st.download_button("ğŸ“¥ ë¶„ì„ ì–‘ì‹(Excel) ë°›ê¸°", f, file_name="keywords_input.xlsx")
    except:
        st.warning("ì„œë²„ì— keywords_input.xlsx íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    st.divider()
    uploaded_file = st.file_uploader("ìˆ˜ì •í•˜ì‹  ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["xlsx"])

# 5. ë©”ì¸ ë¡œì§ ë° íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
if uploaded_file:
    # ìƒˆ íŒŒì¼ì´ ë“¤ì–´ì˜¤ë©´ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ì´ˆê¸°í™”
    if "last_uploaded" not in st.session_state or st.session_state["last_uploaded"] != uploaded_file.name:
        st.session_state["analysis_result"] = None
        st.session_state["last_uploaded"] = uploaded_file.name

    df_input = pd.read_excel(uploaded_file)
    
    if 'GroupName' in df_input.columns:
        # ë°ì´í„° ì „ì²˜ë¦¬: ë©”ëª¨ í–‰(*) ì œì™¸
        all_groups = []
        for _, row in df_input.iterrows():
            g_name = str(row['GroupName']).strip()
            if not g_name or g_name.startswith('*') or g_name == "nan": continue
            kw_val = str(row['Keywords']).strip() if 'Keywords' in df_input.columns and pd.notnull(row['Keywords']) else ""
            keywords = [k.strip() for k in kw_val.split(',')] if kw_val and kw_val != "nan" else [g_name]
            all_groups.append({"groupName": g_name, "keywords": keywords})

        if all_groups:
            anchor_group = all_groups[0]
            anchor_name = anchor_group['groupName']
            other_groups = all_groups[1:]

            if st.sidebar.button("ğŸš€ ë¶„ì„ ì‹œì‘ (Run Analysis)"):
                final_df = pd.DataFrame()
                reference_data = pd.DataFrame()
                status_text = st.empty()
                progress_bar = st.progress(0)
                
                # ë°°ì¹˜ ì²˜ë¦¬ ë° ë¶„ì„ (4ê°œ í‚¤ì›Œë“œì”©)
                batch_size = 4
                for i in range(0, len(other_groups) if other_groups else 1, batch_size):
                    chunk = other_groups[i:i+batch_size]
                    current_batch = [anchor_group] + chunk
                    status_text.text(f"â³ ë¶„ì„ ì¤‘: {', '.join([c['groupName'] for c in chunk])}")
                    
                    # API í˜¸ì¶œ
                    batch_res = pd.concat([get_api_data(current_batch, 'm'), get_api_data(current_batch, 'f')], ignore_index=True)
                    
                    if batch_res.empty: continue

                    if i == 0 or reference_data.empty:
                        reference_data = batch_res[batch_res['Keyword_Group'] == anchor_name].copy()
                        final_df = batch_res
                    else:
                        # ìŠ¤ì¼€ì¼ ë³´ì • ë¡œì§
                        curr_anchor = batch_res[batch_res['Keyword_Group'] == anchor_name].copy()
                        if not curr_anchor.empty:
                            scale_merge = pd.merge(curr_anchor, reference_data, on=['Date', 'Gender'], suffixes=('_curr', '_ref'))
                            if not scale_merge.empty:
                                scale_merge['Factor'] = scale_merge['Ratio_ref'] / scale_merge['Ratio_curr']
                                batch_res = pd.merge(batch_res, scale_merge[['Date', 'Gender', 'Factor']], on=['Date', 'Gender'])
                                batch_res['Ratio'] = batch_res['Ratio'] * batch_res['Factor']
                                final_df = pd.concat([final_df, batch_res[batch_res['Keyword_Group'] != anchor_name]], ignore_index=True)
                    
                    progress_bar.progress(min((i + batch_size) / (len(other_groups) + 1) if other_groups else 1.0, 1.0))

                status_text.empty()
                if not final_df.empty:
                    st.session_state['analysis_result'] = final_df
                    st.session_state['anchor_name'] = anchor_name
                    st.success("âœ… ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                else:
                    st.error("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í‚¤ì›Œë“œë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")

        # 6. ê²°ê³¼ ì‹œê°í™” ë° í•„í„°ë§
        if st.session_state.get('analysis_result') is not None:
            res_df = st.session_state['analysis_result']
            anchor_name = st.session_state['anchor_name']
            
            st.divider()
            st.subheader("ğŸ¯ ê²°ê³¼ í•„í„°ë§ ë° ë‹¤ìš´ë¡œë“œ")
            
            # ë©€í‹° ì„ íƒ í•„í„°
            available_keywords = res_df['Keyword_Group'].unique().tolist()
            selected_items = st.multiselect("í™•ì¸í•  í‚¤ì›Œë“œ ì„ íƒ:", options=available_keywords, default=available_keywords)
            
            if selected_items:
                filtered_df = res_df[res_df['Keyword_Group'].isin(selected_items)]
                
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.subheader(f"ğŸ“Š ê²€ìƒ‰ íŠ¸ë Œë“œ (ê¸°ì¤€: {anchor_name})")
                    chart_data = filtered_df.pivot_table(index='Date', columns='Keyword_Group', values='Ratio', aggfunc='mean')
                    st.line_chart(chart_data)
                
                with col2:
                    st.subheader("ğŸ‘¥ ì„±ë³„ ë¹„ì¤‘ (í‰ê· )")
                    st.write(filtered_df.groupby('Gender')['Ratio'].mean())

                # ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ë³µêµ¬
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    filtered_df.to_excel(writer, index=False, sheet_name='Result')
                st.download_button("ğŸ“¥ ì„ íƒëœ ë¶„ì„ ê²°ê³¼ ì €ì¥", output.getvalue(), file_name=f"freedom_trend_{datetime.now().strftime('%Y%m%d')}.xlsx")
                st.dataframe(filtered_df, use_container_width=True)
    else:
        st.error("ì—‘ì…€ íŒŒì¼ì— 'GroupName' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
else:
    st.info("ì‚¬ì´ë“œë°”ì—ì„œ ì–‘ì‹ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
