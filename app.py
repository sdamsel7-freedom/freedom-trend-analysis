import streamlit as st
import pandas as pd
import urllib.request
import json
from datetime import datetime
import io

# 1. ë³´ì•ˆ ì„¤ì •: Streamlit Cloudì˜ Secrets ë©”ë‰´ì— ì…ë ¥í•œ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
# [Security] Use st.secrets to protect your API keys from public exposure.
try:
    CLIENT_ID = st.secrets["NAVER_CLIENT_ID"]
    CLIENT_SECRET = st.secrets["NAVER_CLIENT_SECRET"]
except KeyError:
    st.error("Error: NAVER_CLIENT_ID and NAVER_CLIENT_SECRET must be set in Streamlit Secrets.")
    st.stop()

st.set_page_config(page_title="Freedom Trend Analysis Dashboard", layout="wide")

# UI ì œëª© ë° ì„¤ëª…
st.title("ğŸƒâ€â™‚ï¸ Freedom Trend Analysis Dashboard")
st.markdown("### 19~44ì„¸ ë‚¨ë…€ íŠ¸ë Œë“œ ë¶„ì„ ë° ìŠ¤ì¼€ì¼ ë³´ì • ë„êµ¬")
st.info("ì—‘ì…€ íŒŒì¼ì˜ ì²« ë²ˆì§¸ í–‰ì´ ëª¨ë“  ë¶„ì„ì˜ 'ê¸°ì¤€ì (Anchor)'ì´ ë©ë‹ˆë‹¤.")

# 2. API í˜¸ì¶œ í•¨ìˆ˜ (Naver DataLab API)
def get_api_data(all_groups, gender):
    url = "https://openapi.naver.com/v1/datalab/search"
    body = {
        "startDate": "2023-01-01", 
        "endDate": "2025-12-31",
        "timeUnit": "month", 
        "keywordGroups": all_groups,
        "device": "", 
        "ages": ["3", "4", "5", "6", "7"], # 19~44ì„¸ í•„í„°
        "gender": gender
    }
    
    req = urllib.request.Request(url)
    req.add_header("X-Naver-Client-Id", CLIENT_ID)
    req.add_header("X-Naver-Client-Secret", CLIENT_SECRET)
    req.add_header("Content-Type", "application/json")
    
    try:
        res = urllib.request.urlopen(req, data=json.dumps(body).encode("utf-8"))
        result = json.loads(res.read().decode('utf-8'))
        data_list = []
        for group in result['results']:
            for entry in group['data']:
                data_list.append({
                    'Date': entry['period'], 
                    'Keyword_Group': group['title'], 
                    'Ratio': entry['ratio'], 
                    'Gender': 'Male' if gender == 'm' else 'Female'
                })
        return pd.DataFrame(data_list)
    except Exception as e:
        st.error(f"API Error: {e}")
        return pd.DataFrame()

# 3. ì‚¬ì´ë“œë°”: íŒŒì¼ ì—…ë¡œë“œ
st.sidebar.header("Upload Data")
uploaded_file = st.sidebar.file_uploader("ë¶„ì„í•  í‚¤ì›Œë“œ ì—‘ì…€(keywords_input.xlsx)ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["xlsx"])

if uploaded_file is not None:
    # ì—‘ì…€ ë°ì´í„° ë¡œë“œ ë° í‚¤ì›Œë“œ ì „ì²˜ë¦¬
    df_input = pd.read_excel(uploaded_file)
    all_keyword_groups = []
    
    for _, row in df_input.iterrows():
        g_name = str(row['GroupName']).strip()
        # [Fallback Logic] Bì—´(Keywords)ì´ ë¹„ì–´ìˆìœ¼ë©´ Aì—´(GroupName)ì„ ê²€ìƒ‰ì–´ë¡œ ì‚¬ìš©
        if pd.isna(row['Keywords']) or str(row['Keywords']).strip() == "":
            keywords = [g_name]
        else:
            keywords = [k.strip() for k in str(row['Keywords']).split(',')]
        all_keyword_groups.append({"groupName": g_name, "keywords": keywords})

    # ê¸°ì¤€ì (Anchor) ì„¤ì •
    anchor_group = all_keyword_groups[0]
    anchor_name = anchor_group['groupName']
    other_groups = all_keyword_groups[1:]

    # ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
    if st.sidebar.button("Run Analysis (ë¶„ì„ ì‹œì‘)"):
        final_df = pd.DataFrame()
        reference_data = pd.DataFrame()
        
        progress_bar = st.progress(0)
        
        # 4ê°œì”© ëŠì–´ì„œ í˜¸ì¶œ (ê¸°ì¤€ì  1ê°œ + ë™ì  í‚¤ì›Œë“œ 4ê°œ = ì´ 5ê°œ ì œí•œ ì¤€ìˆ˜)
        num_batches = (len(other_groups) + 3) // 4 if other_groups else 1
        
        for i in range(0, len(other_groups) if other_groups else 1, 4):
            chunk = other_groups[i:i+4]
            current_batch = [anchor_group] + chunk
            
            # ë‚¨ì„±/ì—¬ì„± ë°ì´í„° ìˆ˜ì§‘
            batch_res = pd.concat([get_api_data(current_batch, 'm'), get_api_data(current_batch, 'f')], ignore_index=True)
            
            if i == 0:
                # ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ ê¸°ì¤€ì  ë°ì´í„°ë¥¼ ë ˆí¼ëŸ°ìŠ¤ë¡œ ê³ ì •
                reference_data = batch_res[batch_res['Keyword_Group'] == anchor_name].drop_duplicates(subset=['Date', 'Gender']).copy()
                final_df = batch_res
            else:
                # ìŠ¤ì¼€ì¼ ë³´ì •(Rescaling) ê³¼ì •
                curr_fixed = batch_res[batch_res['Keyword_Group'] == anchor_name].drop_duplicates(subset=['Date', 'Gender']).copy()
                scale_merge = pd.merge(curr_fixed, reference_data, on=['Date', 'Gender'], suffixes=('_curr', '_ref'))
                scale_merge['Scale_Factor'] = scale_merge['Ratio_ref'] / scale_merge['Ratio_curr']
                
                batch_res = pd.merge(batch_res, scale_merge[['Date', 'Gender', 'Scale_Factor']], on=['Date', 'Gender'])
                batch_res['Ratio'] = batch_res['Ratio'] * batch_res['Scale_Factor']
                
                # ê¸°ì¤€ì  ì¤‘ë³µ ì œê±° í›„ ë³‘í•©
                final_df = pd.concat([final_df, batch_res[batch_res['Keyword_Group'] != anchor_name]], ignore_index=True)
            
            progress_bar.progress(min((i + 4) / (len(other_groups) + 1) if other_groups else 1.0, 1.0))

        if not final_df.empty:
            final_df = final_df.drop_duplicates(subset=['Date', 'Keyword_Group', 'Gender'])
            
            # ê²°ê³¼ í™”ë©´ ì¶œë ¥
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.subheader(f"ğŸ“Š {anchor_name} ëŒ€ë¹„ ìƒëŒ€ ê²€ìƒ‰ëŸ‰ íŠ¸ë Œë“œ")
                # ì‹œê°í™”ë¥¼ ìœ„í•´ í”¼ë²— (ì„±ë³„ í‰ê· ê°’ ê¸°ì¤€)
                chart_data = final_df.pivot_table(index='Date', columns='Keyword_Group', values='Ratio', aggfunc='mean')
                st.line_chart(chart_data)
            
            with col2:
                st.subheader("ğŸ“‹ ì„±ë³„ ê²€ìƒ‰ ë¹„ì¤‘ (í‰ê· )")
                gender_pie = final_df.groupby('Gender')['Ratio'].sum()
                st.write(gender_pie)

            # ë°ì´í„° í…Œì´ë¸”
            st.subheader("ì „ì²´ ë¶„ì„ ë°ì´í„°")
            st.dataframe(final_df, use_container_width=True)

            # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ íŒŒì¼ ìƒì„±
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                final_df.to_excel(writer, index=False, sheet_name='Analysis_Result')
            
            st.download_button(
                label="ğŸ“¥ ë¶„ì„ ê²°ê³¼ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ (Download Excel)",
                data=output.getvalue(),
                file_name=f"freedom_trend_{datetime.now().strftime('%Y%m%d')}.xlsx",
                mime="application/vnd.ms-excel"
            )
else:
    st.warning("ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")