import streamlit as st
import pandas as pd
import requests
import json
from datetime import datetime
import io

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="í”„ë¦¬ë¤ íŠ¸ë Œë“œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ğŸƒâ€â™‚ï¸ Freedom Trend Analysis Dashboard")

# 2. ë³´ì•ˆ ì„¤ì • (Secrets)
try:
    CLIENT_ID = st.secrets["NAVER_CLIENT_ID"]
    CLIENT_SECRET = st.secrets["NAVER_CLIENT_SECRET"]
except KeyError:
    st.error("ì˜¤ë¥˜: Streamlit Secrets ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# ì—°ë ¹ëŒ€ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
AGE_MAP = {
    "0~12ì„¸": "1", "13~18ì„¸": "2", "19~24ì„¸": "3", "25~29ì„¸": "4",
    "30~34ì„¸": "5", "35~39ì„¸": "6", "40~44ì„¸": "7", "45~49ì„¸": "8",
    "50~54ì„¸": "9", "55~59ì„¸": "10", "60ì„¸ ì´ìƒ": "11"
}

# 3. Naver API í˜¸ì¶œ í•¨ìˆ˜
def get_api_data(keyword_groups, gender, age_codes):
    url = "https://openapi.naver.com/v1/datalab/search"
    headers = {
        "X-Naver-Client-Id": CLIENT_ID,
        "X-Naver-Client-Secret": CLIENT_SECRET,
        "Content-Type": "application/json"
    }
    body = {
        "startDate": "2024-01-01",
        "endDate": datetime.now().strftime("%Y-%m-%d"),
        "timeUnit": "month",
        "keywordGroups": keyword_groups,
        "device": "",
        "ages": age_codes, # [ìˆ˜ì •] ì‚¬ìš©ìê°€ ì„ íƒí•œ ì—°ë ¹ëŒ€ ì½”ë“œ ì ìš©
        "gender": gender
    }
    try:
        response = requests.post(url, headers=headers, data=json.dumps(body), timeout=15)
        if response.status_code == 200:
            res_json = response.json()
            data_list = []
            for group in res_json['results']:
                if 'data' in group and group['data']:
                    for entry in group['data']:
                        data_list.append({
                            'Date': entry['period'],
                            'Keyword_Group': group['title'],
                            'Ratio': entry['ratio'],
                            'Gender': 'Male' if gender == 'm' else 'Female'
                        })
            return pd.DataFrame(data_list)
    except Exception as e:
        st.sidebar.error(f"Error: {e}")
    return pd.DataFrame()

# 4. ì‚¬ì´ë“œë°” êµ¬ì„±
with st.sidebar:
    st.header("ğŸ“ ë°ì´í„° ê´€ë¦¬")
    try:
        with open("keywords_input.xlsx", "rb") as f:
            st.download_button("ğŸ“¥ ë¶„ì„ ì–‘ì‹(Excel) ë°›ê¸°", f, file_name="keywords_input.xlsx")
    except:
        pass
    
    st.divider()
    
    # [ìƒˆ ê¸°ëŠ¥] ì—°ë ¹ëŒ€ ë©€í‹° ì„ íƒ í•„í„°
    st.subheader("ğŸ‘¥ íƒ€ê²Ÿ ì—°ë ¹ëŒ€ ì„¤ì •")
    selected_ages = st.multiselect(
        "ë¶„ì„í•  ì—°ë ¹ëŒ€ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
        options=list(AGE_MAP.keys()),
        default=["19~24ì„¸", "25~29ì„¸", "30~34ì„¸", "35~39ì„¸", "40~44ì„¸"] # í”„ë¦¬ë¤ ê¸°ë³¸ íƒ€ê²Ÿ
    )
    # ì„ íƒëœ í•œê¸€ ë¼ë²¨ì„ API ì½”ë“œë¡œ ë³€í™˜
    age_codes = [AGE_MAP[age] for age in selected_ages]
    
    st.divider()
    uploaded_file = st.file_uploader("ìˆ˜ì •í•˜ì‹  ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["xlsx"])

# 5. ë©”ì¸ ë¶„ì„ ë¡œì§
if uploaded_file:
    df_input = pd.read_excel(uploaded_file)
    name_col = next((c for c in df_input.columns if c.lower() in ['groupname', 'ê·¸ë£¹ëª…', 'í•­ëª©']), None)
    kw_col = next((c for c in df_input.columns if c.lower() in ['keywords', 'í‚¤ì›Œë“œ', 'ì—°ê´€ê²€ìƒ‰ì–´']), None)

    if name_col:
        all_groups = []
        for _, row in df_input.iterrows():
            g_name = str(row[name_col]).strip()
            if not g_name or g_name.startswith('*') or g_name == "nan": continue
            
            keyword_list = [g_name]
            raw_kws = str(row[kw_col]).strip() if kw_col and pd.notnull(row[kw_col]) else ""
            if raw_kws and raw_kws.lower() != "nan":
                extra_kws = [k.strip() for k in raw_kws.split(',') if k.strip()]
                keyword_list.extend(extra_kws)
            
            final_keywords = list(dict.fromkeys(keyword_list))
            all_groups.append({"groupName": g_name, "keywords": final_keywords})

        if all_groups:
            anchor_group = all_groups[0]
            anchor_name = anchor_group['groupName']
            other_groups = all_groups[1:]

            if st.sidebar.button("ğŸš€ ë¶„ì„ ì‹œì‘ (Run Analysis)"):
                if not age_codes:
                    st.error("ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ ì—°ë ¹ëŒ€ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
                else:
                    final_df = pd.DataFrame()
                    reference_data = pd.DataFrame()
                    status = st.empty()
                    progress = st.progress(0)
                    
                    batch_size = 4
                    for i in range(0, len(other_groups) if other_groups else 1, batch_size):
                        chunk = other_groups[i:i+batch_size]
                        current_batch = [anchor_group] + chunk
                        status.text(f"â³ ë¶„ì„ ì¤‘: {anchor_name} + {', '.join([c['groupName'] for c in chunk])}")
                        
                        # [ìˆ˜ì •] ì„ íƒëœ ì—°ë ¹ëŒ€ ì½”ë“œë¥¼ API í•¨ìˆ˜ì— ì „ë‹¬
                        batch_res = pd.concat([
                            get_api_data(current_batch, 'm', age_codes), 
                            get_api_data(current_batch, 'f', age_codes)
                        ], ignore_index=True)
                        
                        if batch_res.empty: continue

                        if i == 0 or reference_data.empty:
                            reference_data = batch_res[batch_res['Keyword_Group'] == anchor_name].copy()
                            final_df = batch_res
                        else:
                            curr_anchor = batch_res[batch_res['Keyword_Group'] == anchor_name].copy()
                            if not curr_anchor.empty and not reference_data.empty:
                                scale_merge = pd.merge(curr_anchor, reference_data, on=['Date', 'Gender'], suffixes=('_curr', '_ref'))
                                if not scale_merge.empty:
                                    scale_merge['Factor'] = scale_merge['Ratio_ref'] / scale_merge['Ratio_curr']
                                    batch_res = pd.merge(batch_res, scale_merge[['Date', 'Gender', 'Factor']], on=['Date', 'Gender'])
                                    batch_res['Ratio'] = batch_res['Ratio'] * batch_res['Factor']
                                    final_df = pd.concat([final_df, batch_res[batch_res['Keyword_Group'] != anchor_name]], ignore_index=True)
                        progress.progress(min((i + batch_size) / (len(other_groups) + 1) if other_groups else 1.0, 1.0))

                    status.empty()
                    if not final_df.empty:
                        st.session_state['analysis_result'] = final_df
                        st.session_state['anchor_name'] = anchor_name
                        st.success("âœ… ë¶„ì„ ì™„ë£Œ!")

        # 6. ê²°ê³¼ ì¶œë ¥
        if st.session_state.get('analysis_result') is not None:
            res_df = st.session_state['analysis_result']
            anchor_name = st.session_state['anchor_name']
            st.divider()
            available = res_df['Keyword_Group'].unique().tolist()
            selected = st.multiselect("ğŸ“ˆ í‘œì‹œí•  í•­ëª© ì„ íƒ:", options=available, default=available)
            if selected:
                f_df = res_df[res_df['Keyword_Group'].isin(selected)]
                chart_data = f_df.pivot_table(index='Date', columns='Keyword_Group', values='Ratio', aggfunc='mean')
                st.line_chart(chart_data)
                
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    f_df.to_excel(writer, index=False, sheet_name='Result')
                st.download_button("ğŸ“¥ ê²°ê³¼ ì—‘ì…€ ì €ì¥", output.getvalue(), file_name=f"freedom_trend_{datetime.now().strftime('%Y%m%d')}.xlsx")
                st.dataframe(f_df, use_container_width=True)
